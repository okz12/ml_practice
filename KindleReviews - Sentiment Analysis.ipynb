{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(\"Kindle_Store_5.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I enjoy vintage books and movies so I enjoyed ...</td>\n",
       "      <td>Nice vintage story</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'd never read any of the Amy Brewster mysteri...</td>\n",
       "      <td>I really liked it.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Darth Maul working under cloak of darkness com...</td>\n",
       "      <td>Darth Maul</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I think I have this one in both book and audio...</td>\n",
       "      <td>Audio and book</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I am not for sure on how much of a difference ...</td>\n",
       "      <td>Possibly Important</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           reviewText             summary  \\\n",
       "0   I enjoy vintage books and movies so I enjoyed ...  Nice vintage story   \n",
       "3   I'd never read any of the Amy Brewster mysteri...  I really liked it.   \n",
       "8   Darth Maul working under cloak of darkness com...          Darth Maul   \n",
       "10  I think I have this one in both book and audio...      Audio and book   \n",
       "14  I am not for sure on how much of a difference ...  Possibly Important   \n",
       "\n",
       "    positive  \n",
       "0       True  \n",
       "3       True  \n",
       "8       True  \n",
       "10      True  \n",
       "14      True  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Negative reviews 1 or 2 stars - Positive reviews 5 stars\n",
    "\n",
    "df = df.drop(['asin', 'helpful', 'reviewTime', 'reviewerID', 'reviewerName', 'unixReviewTime'], axis=1)\n",
    "#df = df[df.overall != 2]\n",
    "df = df[df.overall != 3]\n",
    "df = df[df.overall != 4]\n",
    "df['positive'] = df['overall'] == 5\n",
    "df = df.drop('overall', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Count:57000 Negative Count: 57000\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "reviewList = []\n",
    "max_l = 57000\n",
    "p = n = 0\n",
    "for s, r, t in zip(list(df['summary']), list(df['reviewText']), list(df['positive'])):\n",
    "    if s!=\"\" and r!=\"\":#no empty reviews\n",
    "        if t:\n",
    "            if p<max_l:\n",
    "                reviewList.append((s,r,t))\n",
    "                p+=1\n",
    "        else:\n",
    "            if n<max_l:\n",
    "                reviewList.append((s,r,t))\n",
    "                n+=1\n",
    "#summary, review, if-positive\n",
    "print(\"Positive Count:{} Negative Count: {}\".format(p,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kindlereviews.pkl', 'wb') as f:\n",
    "    pickle.dump(reviewList, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\osman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\osman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\osman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\osman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcess:\n",
    "    \n",
    "    def __init__(self, stem='lemma'):\n",
    "        self.pos_keep = set(\"JJ, JJR, JJS, MD, NN, NNS, NNP, NNPS, PDT, POS, PRP, PRP$, RB, RBR, RBS, RP, UH,\\\n",
    "VB, VBD, VBG, VBN, VBP, VBZ, WDT, WP, WRB, WP$\".split(\", \"))\n",
    "        self.tokenizer = TreebankWordTokenizer()\n",
    "        self.stopWords = set(stopwords.words('english'))\n",
    "\n",
    "        self.lemma = stem == 'lemma'\n",
    "        self.wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "        self.porter_stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "    def process(self, review):\n",
    "        review = review.lower()#lower-case\n",
    "        review = pos_tag(self.tokenizer.tokenize(review))#tokenize and tag\n",
    "        #print(review)\n",
    "        new_review = []\n",
    "        for w, p in review:#remove stopwords and other pos_tags\n",
    "            if w not in self.stopWords and p in self.pos_keep:\n",
    "                new_w = self.wordnet_lemmatizer.lemmatize(w.strip(\".\"))\n",
    "                new_w = self.porter_stemmer.stem(new_w)\n",
    "                new_review.append(new_w)\n",
    "\n",
    "        #remove stopwords and keep certain POS_tags\n",
    "        return new_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I enjoy vintage books and movies so I enjoyed reading this book.  The plot was unusual.  Don't think killing someone in self-defense but leaving the scene and the body without notifying the police or hitting someone in the jaw to knock them out would wash today.Still it was a good read for me.\n",
      "enjoy vintag book movi enjoy read book plot unusu n't kill someon self-defens leav scene bodi notifi polic hit someon jaw would good read\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('kindlereviews.pkl', 'rb') as f:\n",
    "    reviews = pickle.load(f)\n",
    "    \n",
    "pp=PreProcess()\n",
    "    \n",
    "print(reviews[0][1])\n",
    "print(\" \".join(pp.process(reviews[0][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import threading#takes a while\n",
    "def process_worker(i,n):\n",
    "    for idx in range(n*i, n*(i+1)):\n",
    "        s = pp.process(reviews[idx][0])\n",
    "        r = pp.process(reviews[idx][1])\n",
    "        t = reviews[idx][2]\n",
    "        \n",
    "        reviews[idx] = (\"DONE\", s,r,t)\n",
    "        \n",
    "t=[]\n",
    "num_w = 4\n",
    "n = len(reviews)//num_w\n",
    "for i in range(num_w):\n",
    "    t.append(threading.Thread(target=process_worker, args=(i,n)))\n",
    "    \n",
    "for i in range(num_w):\n",
    "    t[i].start()\n",
    "    \n",
    "for i in range(num_w):\n",
    "    t[i].join()\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_processed = []\n",
    "\n",
    "for idx, r in enumerate(reviews):\n",
    "    if r[0]==\"DONE\":\n",
    "        reviews_processed.append((r[1],r[2],r[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kindlereviews_processed.pkl', 'wb') as f:\n",
    "    pickle.dump(reviews_processed, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary and Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('kindlereviews_processed.pkl', 'rb') as f:\n",
    "    reviews_processed = pickle.load(f)\n",
    "full_reviews = [x[1] for x in reviews_processed]\n",
    "predictions = [x[2] for x in reviews_processed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(full_reviews, predictions, test_size=0.2)\n",
    "\n",
    "all_words = []\n",
    "for r in X_train:\n",
    "    all_words.extend(r)\n",
    "    \n",
    "from collections import Counter\n",
    "word_counts = Counter(all_words)\n",
    "vocab_list = list(word_counts.most_common(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count Vectorizer function\n",
    "vocabulary = {}\n",
    "idx = 0\n",
    "for x in vocab_list:\n",
    "    vocabulary[x[0]] = idx\n",
    "    idx+=1\n",
    "            \n",
    "#filter\n",
    "for idx in range(len(X_train)):\n",
    "    X_train[idx] = \" \".join( list(filter(lambda x: x in vocabulary, X_train[idx])))\n",
    "\n",
    "for idx in range(len(X_test)):\n",
    "    X_test[idx] = \" \".join( list(filter(lambda x: x in vocabulary, X_test[idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape\n",
    "\n",
    "X_test_counts = count_vect.transform(X_test)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def get_accuracy(clf):\n",
    "    preds = clf.predict(X_test_tfidf)\n",
    "    return accuracy_score(preds, y_test) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-Bayes classifier accuracy is 89.72%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "print (\"Naive-Bayes classifier accuracy is {:.2f}%\".format(get_accuracy(nb_clf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier accuracy is 85.06%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_classifier = RandomForestClassifier(min_samples_leaf=20).fit(X_train_tfidf, y_train)\n",
    "\n",
    "print (\"Random Forest classifier accuracy is {:.2f}%\".format(get_accuracy(forest_classifier)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svm_classifier = svm.SVC(gamma=0.001,kernel='rbf').fit(X_train_tfidf, y_train)#RBF kernel\n",
    "\n",
    "print (\"SVM accuracy is {:.2f}%\".format(get_accuracy(svm_classifier)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
